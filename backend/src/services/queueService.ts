import Bull from 'bull';
import Redis from 'ioredis';
import { DocumentService } from './documentService';
import { VectorService } from './vectorService';
import fs from 'fs';
// @ts-ignore
import pdfParse from 'pdf-parse';

// Redisé…ç½®
const REDIS_URL = process.env.REDIS_URL || 'redis://localhost:6379';
let redis: Redis | null = null;

// åˆå§‹åŒ–Redisè¿æ¥
try {
  // æš‚æ—¶ç¦ç”¨Redisè¿æ¥ï¼Œç›´æ¥ä½¿ç”¨å†…å­˜é˜Ÿåˆ—
  const useRedis = false; // è®¾ç½®ä¸ºfalseä»¥ç¦ç”¨Redis
  if (useRedis && (process.env.REDIS_URL || process.env.NODE_ENV === 'production')) {
    redis = new Redis(REDIS_URL);
    console.log('âœ… Redisé˜Ÿåˆ—æœåŠ¡å·²åˆå§‹åŒ–');
  } else {
    console.warn('âš ï¸  Redisæœªé…ç½®ï¼Œå°†ä½¿ç”¨å†…å­˜é˜Ÿåˆ—');
  }
} catch (error) {
  console.error('âŒ Redisè¿æ¥å¤±è´¥:', error);
  console.warn('âš ï¸  å°†ä½¿ç”¨å†…å­˜é˜Ÿåˆ—ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ');
}

// é˜Ÿåˆ—é…ç½®
const queueOptions = redis ? {
  redis: {
    port: 6379,
    host: 'localhost',
  }
} : undefined;

// åˆ›å»ºé˜Ÿåˆ—
export const documentProcessingQueue = redis ? 
  new Bull('document processing', queueOptions) : 
  null;

// å†…å­˜é˜Ÿåˆ—å¤‡é€‰æ–¹æ¡ˆ
interface MemoryJob {
  id: string;
  data: any;
  status: 'waiting' | 'active' | 'completed' | 'failed';
  progress: number;
  result?: any;
  error?: string;
  createdAt: Date;
  updatedAt: Date;
}

const memoryJobs = new Map<string, MemoryJob>();
const memoryQueue: MemoryJob[] = [];
let isProcessing = false;
let jobIdCounter = 1;

// ä»»åŠ¡ç±»å‹
export enum JobType {
  PROCESS_SINGLE_DOCUMENT = 'process_single_document',
  PROCESS_BATCH_DOCUMENTS = 'process_batch_documents',
  GENERATE_SUMMARY = 'generate_summary',
  EXTRACT_KEYWORDS = 'extract_keywords',
  VECTORIZE_DOCUMENT = 'vectorize_document',
}

// ä»»åŠ¡æ•°æ®æ¥å£
export interface DocumentProcessingJobData {
  type: JobType;
  batchId?: string;
  userId?: string;
  files: Array<{
    fileId: string;
    originalName: string;
    filePath: string;
    fileSize: number;
    mimeType: string;
  }>;
  options?: {
    generateSummary?: boolean;
    extractKeywords?: boolean;
    vectorize?: boolean;
    deleteAfterProcessing?: boolean;
  };
}

export interface JobProgress {
  jobId: string;
  batchId?: string;
  status: 'waiting' | 'active' | 'completed' | 'failed';
  progress: number;
  total: number;
  processed: number;
  failed: number;
  currentFile?: string;
  result?: any;
  error?: string;
  createdAt: Date;
  updatedAt: Date;
}

export class QueueService {
  // æ·»åŠ æ–‡æ¡£å¤„ç†ä»»åŠ¡
  static async addDocumentProcessingJob(data: DocumentProcessingJobData): Promise<string> {
    if (documentProcessingQueue) {
      try {
        const job = await documentProcessingQueue.add(data.type, data, {
          attempts: 3,
          backoff: {
            type: 'exponential',
            delay: 2000,
          },
          removeOnComplete: 10,
          removeOnFail: 5,
        });
        return job.id.toString();
      } catch (error) {
        console.error('æ·»åŠ é˜Ÿåˆ—ä»»åŠ¡å¤±è´¥ï¼Œé™çº§åˆ°å†…å­˜é˜Ÿåˆ—:', error);
        return this.addMemoryJob(data);
      }
    } else {
      return this.addMemoryJob(data);
    }
  }

  // å†…å­˜é˜Ÿåˆ—æ·»åŠ ä»»åŠ¡
  private static addMemoryJob(data: DocumentProcessingJobData): string {
    const jobId = `job_${jobIdCounter++}`;
    const now = new Date();
    
    const memoryJob: MemoryJob = {
      id: jobId,
      data,
      status: 'waiting',
      progress: 0,
      createdAt: now,
      updatedAt: now,
    };
    
    memoryJobs.set(jobId, memoryJob);
    memoryQueue.push(memoryJob);
    
    // å¯åŠ¨å†…å­˜é˜Ÿåˆ—å¤„ç†
    this.processMemoryQueue();
    
    return jobId;
  }

  // å¤„ç†å†…å­˜é˜Ÿåˆ—
  private static async processMemoryQueue(): Promise<void> {
    if (isProcessing || memoryQueue.length === 0) return;
    
    isProcessing = true;
    
    while (memoryQueue.length > 0) {
      const job = memoryQueue.shift();
      if (!job) break;
      
      try {
        job.status = 'active';
        job.updatedAt = new Date();
        
        const result = await this.processJob(job.data, (progress) => {
          job.progress = progress;
          job.updatedAt = new Date();
        });
        
        job.status = 'completed';
        job.result = result;
        job.progress = 100;
        job.updatedAt = new Date();
        
      } catch (error) {
        job.status = 'failed';
        job.error = error instanceof Error ? error.message : String(error);
        job.updatedAt = new Date();
        console.error(`å†…å­˜é˜Ÿåˆ—ä»»åŠ¡ ${job.id} å¤±è´¥:`, error);
      }
    }
    
    isProcessing = false;
  }

  // å¤„ç†ä»»åŠ¡
  private static async processJob(
    data: DocumentProcessingJobData, 
    progressCallback: (progress: number) => void
  ): Promise<any> {
    const { type, files, options = {} } = data;
    const results: any[] = [];
    
    for (let i = 0; i < files.length; i++) {
      const file = files[i];
      if (!file) continue;

      progressCallback(Math.round((i / files.length) * 100));

      try {
        let textContent = '';
        let pageCount = 1;

        // è§£ææ–‡ä»¶å†…å®¹
        if (file.mimeType === 'application/pdf') {
          const dataBuffer = fs.readFileSync(file.filePath);
          const pdfData = await pdfParse(dataBuffer);
          pageCount = pdfData.numpages;
          textContent = pdfData.text;
        } else if (file.mimeType === 'text/plain') {
          textContent = fs.readFileSync(file.filePath, 'utf-8');
        }

        // åˆ›å»ºæ–‡æ¡£è®°å½•
        const document = await DocumentService.createDocument({
          file_id: file.fileId,
          original_name: file.originalName,
          file_size: file.fileSize,
          page_count: pageCount,
          text_content: textContent,
          file_path: file.filePath,
          user_id: data.userId,
        });

        const fileResult: any = {
          fileId: file.fileId,
          originalName: file.originalName,
          status: 'completed',
          document: {
            id: document.id,
            file_id: document.file_id,
            page_count: document.page_count,
            file_size: Number(document.file_size),
          }
        };

        // å¯é€‰å¤„ç†
        if (options.vectorize && textContent) {
          try {
            await VectorService.processDocumentVectorization(document.id, textContent);
            fileResult.vectorized = true;
          } catch (error) {
            console.warn(`æ–‡æ¡£ ${file.fileId} å‘é‡åŒ–å¤±è´¥:`, error);
            fileResult.vectorized = false;
          }
        }

        // åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if (options.deleteAfterProcessing) {
          try {
            fs.unlinkSync(file.filePath);
          } catch (error) {
            console.warn(`åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: ${file.filePath}`, error);
          }
        }

        results.push(fileResult);

      } catch (error) {
        console.error(`å¤„ç†æ–‡ä»¶ ${file.originalName} å¤±è´¥:`, error);
        results.push({
          fileId: file.fileId,
          originalName: file.originalName,
          status: 'failed',
          error: error instanceof Error ? error.message : String(error),
        });
      }
    }
    
    progressCallback(100);
    return {
      batchId: data.batchId,
      totalFiles: files.length,
      processedFiles: results.filter(r => r.status === 'completed').length,
      failedFiles: results.filter(r => r.status === 'failed').length,
      results,
    };
  }

  // è·å–ä»»åŠ¡çŠ¶æ€
  static async getJobStatus(jobId: string): Promise<JobProgress | null> {
    if (documentProcessingQueue) {
      try {
        const job = await documentProcessingQueue.getJob(jobId);
        if (!job) return null;

        return {
          jobId: job.id.toString(),
          batchId: job.data.batchId,
          status: job.finishedOn ? 'completed' : job.failedReason ? 'failed' : job.processedOn ? 'active' : 'waiting',
          progress: 0, // ç®€åŒ–å¤„ç†
          total: job.data.files?.length || 0,
          processed: 0, // éœ€è¦ä»ç»“æœä¸­è®¡ç®—
          failed: 0, // éœ€è¦ä»ç»“æœä¸­è®¡ç®—
          currentFile: job.data.currentFile,
          result: job.returnvalue,
          error: job.failedReason,
          createdAt: new Date(job.timestamp),
          updatedAt: new Date(job.processedOn || job.timestamp),
        };
      } catch (error) {
        console.error('è·å–é˜Ÿåˆ—ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼Œå°è¯•å†…å­˜é˜Ÿåˆ—:', error);
        return this.getMemoryJobStatus(jobId);
      }
    } else {
      return this.getMemoryJobStatus(jobId);
    }
  }

  // è·å–å†…å­˜ä»»åŠ¡çŠ¶æ€
  private static getMemoryJobStatus(jobId: string): JobProgress | null {
    const job = memoryJobs.get(jobId);
    if (!job) return null;
    
    const total = job.data.files?.length || 0;
    const processed = job.result?.processedFiles || 0;
    const failed = job.result?.failedFiles || 0;
    
    return {
      jobId: job.id,
      batchId: job.data.batchId,
      status: job.status,
      progress: job.progress,
      total,
      processed,
      failed,
      result: job.result,
      error: job.error,
      createdAt: job.createdAt,
      updatedAt: job.updatedAt,
    };
  }

  // è·å–æ‰¹é‡ä»»åŠ¡çŠ¶æ€
  static async getBatchStatus(batchId: string): Promise<JobProgress[]> {
    const jobs: JobProgress[] = [];
    
    if (documentProcessingQueue) {
      try {
        const waiting = await documentProcessingQueue.getWaiting();
        const active = await documentProcessingQueue.getActive();
        const completed = await documentProcessingQueue.getCompleted();
        const failed = await documentProcessingQueue.getFailed();
        
        const allJobs = [...waiting, ...active, ...completed, ...failed];
        
        for (const job of allJobs) {
          if (job.data.batchId === batchId) {
            const status = await this.getJobStatus(job.id.toString());
            if (status) jobs.push(status);
          }
        }
      } catch (error) {
        console.error('è·å–æ‰¹é‡ä»»åŠ¡çŠ¶æ€å¤±è´¥ï¼Œå°è¯•å†…å­˜é˜Ÿåˆ—:', error);
      }
    }
    
    // æ£€æŸ¥å†…å­˜é˜Ÿåˆ—
    for (const [jobId, job] of memoryJobs.entries()) {
      if (job.data.batchId === batchId) {
        const status = this.getMemoryJobStatus(jobId);
        if (status) jobs.push(status);
      }
    }
    
    return jobs;
  }

  // å–æ¶ˆä»»åŠ¡
  static async cancelJob(jobId: string): Promise<boolean> {
    if (documentProcessingQueue) {
      try {
        const job = await documentProcessingQueue.getJob(jobId);
        if (job) {
          await job.remove();
          return true;
        }
      } catch (error) {
        console.error('å–æ¶ˆé˜Ÿåˆ—ä»»åŠ¡å¤±è´¥:', error);
      }
    }
    
    // å–æ¶ˆå†…å­˜ä»»åŠ¡
    const job = memoryJobs.get(jobId);
    if (job && job.status === 'waiting') {
      const index = memoryQueue.findIndex(j => j.id === jobId);
      if (index !== -1) {
        memoryQueue.splice(index, 1);
        memoryJobs.delete(jobId);
        return true;
      }
    }
    
    return false;
  }

  // æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
  static async cleanupJobs(): Promise<void> {
    if (documentProcessingQueue) {
      try {
        await documentProcessingQueue.clean(24 * 60 * 60 * 1000, 'completed'); // æ¸…ç†24å°æ—¶å‰çš„å·²å®Œæˆä»»åŠ¡
        await documentProcessingQueue.clean(7 * 24 * 60 * 60 * 1000, 'failed'); // æ¸…ç†7å¤©å‰çš„å¤±è´¥ä»»åŠ¡
      } catch (error) {
        console.error('æ¸…ç†é˜Ÿåˆ—ä»»åŠ¡å¤±è´¥:', error);
      }
    }
    
    // æ¸…ç†å†…å­˜ä»»åŠ¡
    const now = new Date();
    const oneDayAgo = new Date(now.getTime() - 24 * 60 * 60 * 1000);
    
    for (const [jobId, job] of memoryJobs.entries()) {
      if (job.status === 'completed' && job.updatedAt < oneDayAgo) {
        memoryJobs.delete(jobId);
      }
    }
  }

  // è·å–é˜Ÿåˆ—ç»Ÿè®¡
  static async getQueueStats(): Promise<{
    waiting: number;
    active: number;
    completed: number;
    failed: number;
    total: number;
  }> {
    if (documentProcessingQueue) {
      try {
        const [waiting, active, completed, failed] = await Promise.all([
          documentProcessingQueue.getWaiting(),
          documentProcessingQueue.getActive(),
          documentProcessingQueue.getCompleted(),
          documentProcessingQueue.getFailed(),
        ]);
        
        return {
          waiting: waiting.length,
          active: active.length,
          completed: completed.length,
          failed: failed.length,
          total: waiting.length + active.length + completed.length + failed.length,
        };
      } catch (error) {
        console.error('è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥:', error);
      }
    }
    
    // å†…å­˜é˜Ÿåˆ—ç»Ÿè®¡
    const stats = { waiting: 0, active: 0, completed: 0, failed: 0, total: 0 };
    
    for (const job of memoryJobs.values()) {
      stats[job.status]++;
      stats.total++;
    }
    
    return stats;
  }
}

// å¦‚æœä½¿ç”¨Redisé˜Ÿåˆ—ï¼Œè®¾ç½®ä»»åŠ¡å¤„ç†å™¨
if (documentProcessingQueue) {
  documentProcessingQueue.process('*', async (job) => {
    return await QueueService['processJob'](job.data, (progress) => {
      job.progress(progress);
    });
  });
  
  // é˜Ÿåˆ—äº‹ä»¶ç›‘å¬
  documentProcessingQueue.on('completed', (job, result) => {
    console.log(`âœ… ä»»åŠ¡ ${job.id} å®Œæˆ:`, result.totalFiles, 'ä¸ªæ–‡ä»¶å¤„ç†å®Œæˆ');
  });
  
  documentProcessingQueue.on('failed', (job, err) => {
    console.error(`âŒ ä»»åŠ¡ ${job.id} å¤±è´¥:`, err.message);
  });
  
  documentProcessingQueue.on('progress', (job, progress) => {
    console.log(`ğŸ“Š ä»»åŠ¡ ${job.id} è¿›åº¦: ${progress}%`);
  });
}
